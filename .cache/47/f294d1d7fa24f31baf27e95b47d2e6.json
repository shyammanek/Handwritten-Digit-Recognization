{"id":"node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js","dependencies":[{"name":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adamax_optimizer.js.map","includedInParent":true,"mtime":499162500000},{"name":"E:\\htr-final\\package.json","includedInParent":true,"mtime":1603094551417},{"name":"E:\\htr-final\\.babelrc","includedInParent":true,"mtime":1603022514142},{"name":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\package.json","includedInParent":true,"mtime":1603088140582},{"name":"../environment","loc":{"line":13,"column":28},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adamax_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\environment.js"},{"name":"../globals","loc":{"line":14,"column":24},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adamax_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\globals.js"},{"name":"../ops/ops","loc":{"line":15,"column":20},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adamax_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\ops.js"},{"name":"../serialization","loc":{"line":16,"column":30},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adamax_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\serialization.js"},{"name":"./optimizer","loc":{"line":17,"column":26},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adamax_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\optimizer.js"}],"generated":{"js":"\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../environment\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar optimizer_1 = require(\"./optimizer\");\nvar AdamaxOptimizer = (function (_super) {\n    __extends(AdamaxOptimizer, _super);\n    function AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay) {\n        if (epsilon === void 0) { epsilon = null; }\n        if (decay === void 0) { decay = 0.0; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.beta1 = beta1;\n        _this.beta2 = beta2;\n        _this.epsilon = epsilon;\n        _this.decay = decay;\n        _this.accumulatedFirstMoment = {};\n        _this.accumulatedWeightedInfNorm = {};\n        _this.c = globals_1.keep(ops_1.scalar(-learningRate));\n        _this.beta1Scalar = globals_1.keep(ops_1.scalar(beta1));\n        _this.beta2Scalar = globals_1.keep(ops_1.scalar(beta2));\n        _this.decayScalar = globals_1.keep(ops_1.scalar(decay));\n        globals_1.tidy(function () {\n            _this.iteration = ops_1.scalar(0).variable();\n            _this.accBeta1 = ops_1.scalar(beta1).variable();\n        });\n        _this.oneMinusBeta1 = globals_1.keep(ops_1.scalar(1 - beta1));\n        _this.one = globals_1.keep(ops_1.scalar(1));\n        if (epsilon === null) {\n            epsilon = environment_1.ENV.get('EPSILON');\n        }\n        _this.epsScalar = globals_1.keep(ops_1.scalar(epsilon));\n        return _this;\n    }\n    AdamaxOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        globals_1.tidy(function () {\n            var oneMinusAccBeta1 = _this.one.sub(_this.accBeta1);\n            var lr = _this.c.div(_this.one.add(_this.decayScalar.mul(_this.iteration)));\n            for (var variableName in variableGradients) {\n                var value = environment_1.ENV.engine.registeredVariables[variableName];\n                if (_this.accumulatedFirstMoment[variableName] == null) {\n                    var trainable = false;\n                    _this.accumulatedFirstMoment[variableName] =\n                        ops_1.zerosLike(value).variable(trainable);\n                }\n                if (_this.accumulatedWeightedInfNorm[variableName] == null) {\n                    var trainable = false;\n                    _this.accumulatedWeightedInfNorm[variableName] =\n                        ops_1.zerosLike(value).variable(trainable);\n                }\n                var gradient = variableGradients[variableName];\n                var firstMoment = _this.accumulatedFirstMoment[variableName];\n                var weightedInfNorm = _this.accumulatedWeightedInfNorm[variableName];\n                var newFirstMoment = _this.beta1Scalar.mul(firstMoment)\n                    .add(_this.oneMinusBeta1.mul(gradient));\n                var ut0 = _this.beta2Scalar.mul(weightedInfNorm);\n                var ut1 = gradient.abs();\n                var newWeightedInfNorm = ut0.maximum(ut1);\n                _this.accumulatedFirstMoment[variableName].assign(newFirstMoment);\n                _this.accumulatedWeightedInfNorm[variableName].assign(newWeightedInfNorm);\n                var newValue = lr.div(oneMinusAccBeta1)\n                    .mul(newFirstMoment.div(_this.epsScalar.add(newWeightedInfNorm)))\n                    .add(value);\n                value.assign(newValue);\n            }\n            _this.iteration.assign(_this.iteration.add(_this.one));\n            _this.accBeta1.assign(_this.accBeta1.mul(_this.beta1Scalar));\n        });\n    };\n    AdamaxOptimizer.prototype.dispose = function () {\n        var _this = this;\n        this.c.dispose();\n        this.epsScalar.dispose();\n        this.accBeta1.dispose();\n        this.beta1Scalar.dispose();\n        this.beta2Scalar.dispose();\n        this.oneMinusBeta1.dispose();\n        this.decayScalar.dispose();\n        this.iteration.dispose();\n        this.one.dispose();\n        if (this.accumulatedFirstMoment != null) {\n            Object.keys(this.accumulatedFirstMoment)\n                .forEach(function (name) { return _this.accumulatedFirstMoment[name].dispose(); });\n        }\n        if (this.accumulatedWeightedInfNorm != null) {\n            Object.keys(this.accumulatedWeightedInfNorm)\n                .forEach(function (name) { return _this.accumulatedWeightedInfNorm[name].dispose(); });\n        }\n    };\n    AdamaxOptimizer.prototype.getConfig = function () {\n        return {\n            learningRate: this.learningRate,\n            beta1: this.beta1,\n            beta2: this.beta2,\n            epsilon: this.epsilon,\n            decay: this.decay\n        };\n    };\n    AdamaxOptimizer.fromConfig = function (cls, config) {\n        return new cls(config.learningRate, config.beta1, config.beta2, config.epsilon, config.decay);\n    };\n    AdamaxOptimizer.className = 'AdamaxOptimizer';\n    return AdamaxOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdamaxOptimizer = AdamaxOptimizer;\nserialization_1.registerClass(AdamaxOptimizer);\n"},"sourceMaps":{"js":{"version":3,"file":"adamax_optimizer.js","sourceRoot":"","sources":["../../src/optimizers/adamax_optimizer.ts"],"names":[],"mappings":";;;;;;;;;;;;AAiBA,8CAAmC;AACnC,sCAAsC;AACtC,kCAA6C;AAC7C,kDAAkG;AAGlG,yCAAsC;AAEtC;IAAqC,mCAAS;IAe5C,yBACc,YAAoB,EAAY,KAAa,EAC7C,KAAa,EAAY,OAAsB,EAC/C,KAAW;QADc,wBAAA,EAAA,cAAsB;QAC/C,sBAAA,EAAA,WAAW;QAHzB,YAIE,iBAAO,SAsBR;QAzBa,kBAAY,GAAZ,YAAY,CAAQ;QAAY,WAAK,GAAL,KAAK,CAAQ;QAC7C,WAAK,GAAL,KAAK,CAAQ;QAAY,aAAO,GAAP,OAAO,CAAe;QAC/C,WAAK,GAAL,KAAK,CAAM;QANjB,4BAAsB,GAAqB,EAAE,CAAC;QAC9C,gCAA0B,GAAqB,EAAE,CAAC;QAOxD,KAAI,CAAC,CAAC,GAAG,cAAI,CAAC,YAAM,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC;QAGrC,KAAI,CAAC,WAAW,GAAG,cAAI,CAAC,YAAM,CAAC,KAAK,CAAC,CAAC,CAAC;QACvC,KAAI,CAAC,WAAW,GAAG,cAAI,CAAC,YAAM,CAAC,KAAK,CAAC,CAAC,CAAC;QAEvC,KAAI,CAAC,WAAW,GAAG,cAAI,CAAC,YAAM,CAAC,KAAK,CAAC,CAAC,CAAC;QAEvC,cAAI,CAAC;YACH,KAAI,CAAC,SAAS,GAAG,YAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,EAAE,CAAC;YACtC,KAAI,CAAC,QAAQ,GAAG,YAAM,CAAC,KAAK,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC3C,CAAC,CAAC,CAAC;QAEH,KAAI,CAAC,aAAa,GAAG,cAAI,CAAC,YAAM,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;QAC7C,KAAI,CAAC,GAAG,GAAG,cAAI,CAAC,YAAM,CAAC,CAAC,CAAC,CAAC,CAAC;QAE3B,IAAI,OAAO,KAAK,IAAI,EAAE;YACpB,OAAO,GAAG,iBAAG,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC;SAC9B;QAED,KAAI,CAAC,SAAS,GAAG,cAAI,CAAC,YAAM,CAAC,OAAO,CAAC,CAAC,CAAC;;IACzC,CAAC;IAED,wCAAc,GAAd,UAAe,iBAAmC;QAAlD,iBA6CC;QA5CC,cAAI,CAAC;YACH,IAAM,gBAAgB,GAAG,KAAI,CAAC,GAAG,CAAC,GAAG,CAAC,KAAI,CAAC,QAAQ,CAAC,CAAC;YACrD,IAAM,EAAE,GAAG,KAAI,CAAC,CAAC,CAAC,GAAG,CAAC,KAAI,CAAC,GAAG,CAAC,GAAG,CAAC,KAAI,CAAC,WAAW,CAAC,GAAG,CAAC,KAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;YAE1E,KAAK,IAAM,YAAY,IAAI,iBAAiB,EAAE;gBAC5C,IAAM,KAAK,GAAG,iBAAG,CAAC,MAAM,CAAC,mBAAmB,CAAC,YAAY,CAAC,CAAC;gBAC3D,IAAI,KAAI,CAAC,sBAAsB,CAAC,YAAY,CAAC,IAAI,IAAI,EAAE;oBACrD,IAAM,SAAS,GAAG,KAAK,CAAC;oBACxB,KAAI,CAAC,sBAAsB,CAAC,YAAY,CAAC;wBACrC,eAAS,CAAC,KAAK,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;iBAC1C;gBACD,IAAI,KAAI,CAAC,0BAA0B,CAAC,YAAY,CAAC,IAAI,IAAI,EAAE;oBACzD,IAAM,SAAS,GAAG,KAAK,CAAC;oBACxB,KAAI,CAAC,0BAA0B,CAAC,YAAY,CAAC;wBACzC,eAAS,CAAC,KAAK,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;iBAC1C;gBAED,IAAM,QAAQ,GAAG,iBAAiB,CAAC,YAAY,CAAC,CAAC;gBACjD,IAAM,WAAW,GAAG,KAAI,CAAC,sBAAsB,CAAC,YAAY,CAAC,CAAC;gBAC9D,IAAM,eAAe,GAAG,KAAI,CAAC,0BAA0B,CAAC,YAAY,CAAC,CAAC;gBAEtE,IAAM,cAAc,GAAG,KAAI,CAAC,WAAW,CAAC,GAAG,CAAC,WAAW,CAAC;qBAC5B,GAAG,CAAC,KAAI,CAAC,aAAa,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC;gBAElE,IAAM,GAAG,GAAG,KAAI,CAAC,WAAW,CAAC,GAAG,CAAC,eAAe,CAAC,CAAC;gBAClD,IAAM,GAAG,GAAG,QAAQ,CAAC,GAAG,EAAE,CAAC;gBAE3B,IAAM,kBAAkB,GAAG,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC;gBAE5C,KAAI,CAAC,sBAAsB,CAAC,YAAY,CAAC,CAAC,MAAM,CAAC,cAAc,CAAC,CAAC;gBACjE,KAAI,CAAC,0BAA0B,CAAC,YAAY,CAAC,CAAC,MAAM,CAChD,kBAAkB,CAAC,CAAC;gBAExB,IAAM,QAAQ,GACV,EAAE,CAAC,GAAG,CAAC,gBAAgB,CAAC;qBACnB,GAAG,CAAC,cAAc,CAAC,GAAG,CAAC,KAAI,CAAC,SAAS,CAAC,GAAG,CAAC,kBAAkB,CAAC,CAAC,CAAC;qBAC/D,GAAG,CAAC,KAAK,CAAC,CAAC;gBAEpB,KAAK,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAC;aACxB;YAED,KAAI,CAAC,SAAS,CAAC,MAAM,CAAC,KAAI,CAAC,SAAS,CAAC,GAAG,CAAC,KAAI,CAAC,GAAG,CAAC,CAAC,CAAC;YACpD,KAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,KAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,KAAI,CAAC,WAAW,CAAC,CAAC,CAAC;QAC5D,CAAC,CAAC,CAAC;IACL,CAAC;IAED,iCAAO,GAAP;QAAA,iBAsBC;QArBC,IAAI,CAAC,CAAC,CAAC,OAAO,EAAE,CAAC;QACjB,IAAI,CAAC,SAAS,CAAC,OAAO,EAAE,CAAC;QACzB,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAC;QACxB,IAAI,CAAC,WAAW,CAAC,OAAO,EAAE,CAAC;QAC3B,IAAI,CAAC,WAAW,CAAC,OAAO,EAAE,CAAC;QAC3B,IAAI,CAAC,aAAa,CAAC,OAAO,EAAE,CAAC;QAE7B,IAAI,CAAC,WAAW,CAAC,OAAO,EAAE,CAAC;QAC3B,IAAI,CAAC,SAAS,CAAC,OAAO,EAAE,CAAC;QAEzB,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,CAAC;QAEnB,IAAI,IAAI,CAAC,sBAAsB,IAAI,IAAI,EAAE;YACvC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,sBAAsB,CAAC;iBACnC,OAAO,CAAC,UAAA,IAAI,IAAI,OAAA,KAAI,CAAC,sBAAsB,CAAC,IAAI,CAAC,CAAC,OAAO,EAAE,EAA3C,CAA2C,CAAC,CAAC;SACnE;QAED,IAAI,IAAI,CAAC,0BAA0B,IAAI,IAAI,EAAE;YAC3C,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,0BAA0B,CAAC;iBACvC,OAAO,CAAC,UAAA,IAAI,IAAI,OAAA,KAAI,CAAC,0BAA0B,CAAC,IAAI,CAAC,CAAC,OAAO,EAAE,EAA/C,CAA+C,CAAC,CAAC;SACvE;IACH,CAAC;IACD,mCAAS,GAAT;QACE,OAAO;YACL,YAAY,EAAE,IAAI,CAAC,YAAY;YAC/B,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,KAAK,EAAE,IAAI,CAAC,KAAK;SAClB,CAAC;IACJ,CAAC;IACM,0BAAU,GAAjB,UACI,GAA+B,EAAE,MAAkB;QACrD,OAAO,IAAI,GAAG,CACV,MAAM,CAAC,YAAY,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,OAAO,EAC/D,MAAM,CAAC,KAAK,CAAC,CAAC;IACpB,CAAC;IA9HM,yBAAS,GAAG,iBAAiB,CAAC;IA+HvC,sBAAC;CAAA,AAhID,CAAqC,qBAAS,GAgI7C;AAhIY,0CAAe;AAiI5B,6BAAa,CAAC,eAAe,CAAC,CAAC","sourcesContent":[null]}},"error":null,"hash":"9a8514da42bbd867f9ec90d57c9f7fc1","cacheData":{"env":{}}}