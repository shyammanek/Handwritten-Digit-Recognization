{"id":"node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js","dependencies":[{"name":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adagrad_optimizer.js.map","includedInParent":true,"mtime":499162500000},{"name":"E:\\htr-final\\package.json","includedInParent":true,"mtime":1603094551417},{"name":"E:\\htr-final\\.babelrc","includedInParent":true,"mtime":1603022514142},{"name":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\package.json","includedInParent":true,"mtime":1603088140582},{"name":"../environment","loc":{"line":13,"column":28},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adagrad_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\environment.js"},{"name":"../globals","loc":{"line":14,"column":24},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adagrad_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\globals.js"},{"name":"../ops/ops","loc":{"line":15,"column":20},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adagrad_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\ops.js"},{"name":"../serialization","loc":{"line":16,"column":30},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adagrad_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\serialization.js"},{"name":"./optimizer","loc":{"line":17,"column":26},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\adagrad_optimizer.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\optimizers\\optimizer.js"}],"generated":{"js":"\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../environment\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar optimizer_1 = require(\"./optimizer\");\nvar AdagradOptimizer = (function (_super) {\n    __extends(AdagradOptimizer, _super);\n    function AdagradOptimizer(learningRate, initialAccumulatorValue) {\n        if (initialAccumulatorValue === void 0) { initialAccumulatorValue = 0.1; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.initialAccumulatorValue = initialAccumulatorValue;\n        _this.accumulatedGrads = {};\n        _this.c = globals_1.keep(ops_1.scalar(-learningRate));\n        _this.epsilon = globals_1.keep(ops_1.scalar(environment_1.ENV.get('EPSILON')));\n        return _this;\n    }\n    AdagradOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var _loop_1 = function (variableName) {\n            var value = environment_1.ENV.engine.registeredVariables[variableName];\n            if (this_1.accumulatedGrads[variableName] == null) {\n                var trainable_1 = false;\n                globals_1.tidy(function () {\n                    _this.accumulatedGrads[variableName] =\n                        ops_1.fill(value.shape, _this.initialAccumulatorValue)\n                            .variable(trainable_1);\n                });\n            }\n            var gradient = variableGradients[variableName];\n            var accumulatedGrad = this_1.accumulatedGrads[variableName];\n            globals_1.tidy(function () {\n                var newAccumulatedGrad = accumulatedGrad.add(gradient.square());\n                _this.accumulatedGrads[variableName].assign(newAccumulatedGrad);\n                var newValue = _this.c\n                    .mul(gradient.div(newAccumulatedGrad.add(_this.epsilon).sqrt()))\n                    .add(value);\n                value.assign(newValue);\n            });\n        };\n        var this_1 = this;\n        for (var variableName in variableGradients) {\n            _loop_1(variableName);\n        }\n    };\n    AdagradOptimizer.prototype.dispose = function () {\n        var _this = this;\n        this.epsilon.dispose();\n        this.c.dispose();\n        if (this.accumulatedGrads != null) {\n            Object.keys(this.accumulatedGrads)\n                .forEach(function (name) { return _this.accumulatedGrads[name].dispose(); });\n        }\n    };\n    AdagradOptimizer.prototype.getConfig = function () {\n        return {\n            learningRate: this.learningRate,\n            initialAccumulatorValue: this.initialAccumulatorValue,\n        };\n    };\n    AdagradOptimizer.fromConfig = function (cls, config) {\n        return new cls(config.learningRate, config.initialAccumulatorValue);\n    };\n    AdagradOptimizer.className = 'AdagradOptimizer';\n    return AdagradOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdagradOptimizer = AdagradOptimizer;\nserialization_1.registerClass(AdagradOptimizer);\n"},"sourceMaps":{"js":{"version":3,"file":"adagrad_optimizer.js","sourceRoot":"","sources":["../../src/optimizers/adagrad_optimizer.ts"],"names":[],"mappings":";;;;;;;;;;;;AAiBA,8CAAmC;AACnC,sCAAsC;AACtC,kCAAwC;AACxC,kDAAkG;AAGlG,yCAAsC;AAGtC;IAAsC,oCAAS;IAO7C,0BACc,YAAoB,EAAU,uBAA6B;QAA7B,wCAAA,EAAA,6BAA6B;QADzE,YAEE,iBAAO,SAIR;QALa,kBAAY,GAAZ,YAAY,CAAQ;QAAU,6BAAuB,GAAvB,uBAAuB,CAAM;QAHjE,sBAAgB,GAAqB,EAAE,CAAC;QAK9C,KAAI,CAAC,CAAC,GAAG,cAAI,CAAC,YAAM,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC;QAErC,KAAI,CAAC,OAAO,GAAG,cAAI,CAAC,YAAM,CAAC,iBAAG,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;;IAClD,CAAC;IAED,yCAAc,GAAd,UAAe,iBAAmC;QAAlD,iBA0BC;gCAzBY,YAAY;YACrB,IAAM,KAAK,GAAG,iBAAG,CAAC,MAAM,CAAC,mBAAmB,CAAC,YAAY,CAAC,CAAC;YAC3D,IAAI,OAAK,gBAAgB,CAAC,YAAY,CAAC,IAAI,IAAI,EAAE;gBAC/C,IAAM,WAAS,GAAG,KAAK,CAAC;gBACxB,cAAI,CAAC;oBACH,KAAI,CAAC,gBAAgB,CAAC,YAAY,CAAC;wBAC/B,UAAI,CAAC,KAAK,CAAC,KAAK,EAAE,KAAI,CAAC,uBAAuB,CAAC;6BAC1C,QAAQ,CAAC,WAAS,CAAC,CAAC;gBAC/B,CAAC,CAAC,CAAC;aACJ;YAED,IAAM,QAAQ,GAAG,iBAAiB,CAAC,YAAY,CAAC,CAAC;YACjD,IAAM,eAAe,GAAG,OAAK,gBAAgB,CAAC,YAAY,CAAC,CAAC;YAE5D,cAAI,CAAC;gBACH,IAAM,kBAAkB,GAAG,eAAe,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAC,CAAC;gBAClE,KAAI,CAAC,gBAAgB,CAAC,YAAY,CAAC,CAAC,MAAM,CAAC,kBAAkB,CAAC,CAAC;gBAE/D,IAAM,QAAQ,GACV,KAAI,CAAC,CAAC;qBACD,GAAG,CAAC,QAAQ,CAAC,GAAG,CAAC,kBAAkB,CAAC,GAAG,CAAC,KAAI,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC;qBAC9D,GAAG,CAAC,KAAK,CAAC,CAAC;gBACpB,KAAK,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAC;YACzB,CAAC,CAAC,CAAC;QACL,CAAC;;QAxBD,KAAK,IAAM,YAAY,IAAI,iBAAiB;oBAAjC,YAAY;SAwBtB;IACH,CAAC;IAED,kCAAO,GAAP;QAAA,iBAOC;QANC,IAAI,CAAC,OAAO,CAAC,OAAO,EAAE,CAAC;QACvB,IAAI,CAAC,CAAC,CAAC,OAAO,EAAE,CAAC;QACjB,IAAI,IAAI,CAAC,gBAAgB,IAAI,IAAI,EAAE;YACjC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,gBAAgB,CAAC;iBAC7B,OAAO,CAAC,UAAA,IAAI,IAAI,OAAA,KAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,CAAC,OAAO,EAAE,EAArC,CAAqC,CAAC,CAAC;SAC7D;IACH,CAAC;IACD,oCAAS,GAAT;QACE,OAAO;YACL,YAAY,EAAE,IAAI,CAAC,YAAY;YAC/B,uBAAuB,EAAE,IAAI,CAAC,uBAAuB;SACtD,CAAC;IACJ,CAAC;IACM,2BAAU,GAAjB,UACI,GAA+B,EAAE,MAAkB;QACrD,OAAO,IAAI,GAAG,CAAC,MAAM,CAAC,YAAY,EAAE,MAAM,CAAC,uBAAuB,CAAC,CAAC;IACtE,CAAC;IA3DM,0BAAS,GAAG,kBAAkB,CAAC;IA4DxC,uBAAC;CAAA,AA7DD,CAAsC,qBAAS,GA6D9C;AA7DY,4CAAgB;AA8D7B,6BAAa,CAAC,gBAAgB,CAAC,CAAC","sourcesContent":[null]}},"error":null,"hash":"71ad42a96fcf2707498f2abbcf52d59d","cacheData":{"env":{}}}