{"id":"node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops.js","dependencies":[{"name":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\loss_ops.js.map","includedInParent":true,"mtime":499162500000},{"name":"E:\\htr-final\\package.json","includedInParent":true,"mtime":1603094551417},{"name":"E:\\htr-final\\.babelrc","includedInParent":true,"mtime":1603022514142},{"name":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\package.json","includedInParent":true,"mtime":1603088140582},{"name":"../globals","loc":{"line":3,"column":24},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\loss_ops.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\globals.js"},{"name":"../tensor_util_env","loc":{"line":4,"column":32},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\loss_ops.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\tensor_util_env.js"},{"name":"../util","loc":{"line":5,"column":21},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\loss_ops.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\util.js"},{"name":"./axis_util","loc":{"line":6,"column":26},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\loss_ops.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\axis_util.js"},{"name":"./binary_ops","loc":{"line":7,"column":27},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\loss_ops.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\binary_ops.js"},{"name":"./operation","loc":{"line":8,"column":26},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\loss_ops.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\operation.js"},{"name":"./tensor_ops","loc":{"line":9,"column":27},"parent":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\loss_ops.js","resolved":"E:\\htr-final\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\tensor_ops.js"}],"generated":{"js":"\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar globals_1 = require(\"../globals\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util_1 = require(\"../util\");\nvar axis_util_1 = require(\"./axis_util\");\nvar binary_ops_1 = require(\"./binary_ops\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\nvar Reduction;\n(function (Reduction) {\n    Reduction[Reduction[\"NONE\"] = 0] = \"NONE\";\n    Reduction[Reduction[\"MEAN\"] = 1] = \"MEAN\";\n    Reduction[Reduction[\"SUM\"] = 2] = \"SUM\";\n    Reduction[Reduction[\"SUM_BY_NONZERO_WEIGHTS\"] = 3] = \"SUM_BY_NONZERO_WEIGHTS\";\n})(Reduction = exports.Reduction || (exports.Reduction = {}));\nfunction computeWeightedLoss_(losses, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $losses = tensor_util_env_1.convertToTensor(losses, 'losses', 'computeWeightedLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'computeWeightedLoss');\n    }\n    var weightedLoss = ($weights == null) ? $losses : $losses.mul($weights);\n    if (reduction === Reduction.NONE) {\n        return weightedLoss;\n    }\n    if (reduction === Reduction.SUM) {\n        return weightedLoss.sum();\n    }\n    if (reduction === Reduction.MEAN) {\n        if ($weights == null) {\n            return weightedLoss.mean();\n        }\n        else {\n            var broadcastFactor = util_1.sizeFromShape($losses.shape) / util_1.sizeFromShape($weights.shape);\n            var result = weightedLoss.sum().div($weights.sum());\n            return broadcastFactor > 1 ? result.div(tensor_ops_1.scalar(broadcastFactor)) :\n                result;\n        }\n    }\n    if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\n        if ($weights == null) {\n            return weightedLoss.sum().div(tensor_ops_1.scalar($losses.size));\n        }\n        else {\n            var broadcastedWeights = $weights.mul(tensor_ops_1.ones($losses.shape));\n            var numNonZeros = broadcastedWeights.notEqual(tensor_ops_1.scalar(0)).sum().toFloat();\n            return weightedLoss.sum().div(numNonZeros);\n        }\n    }\n    throw Error(\"Unknown reduction: \" + reduction);\n}\nfunction absoluteDifference_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'absoluteDifference');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'absoluteDifference');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'absoluteDifference');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in absoluteDifference: ');\n    var losses = $labels.sub($predictions).abs();\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction meanSquaredError_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'meanSquaredError');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'meanSquaredError');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'meanSquaredError');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in meanSquaredError: ');\n    var losses = $labels.squaredDifference($predictions);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction cosineDistance_(labels, predictions, axis, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'cosineDistance');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'cosineDistance');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'cosineDistance');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in cosineDistance: ');\n    var one = tensor_ops_1.scalar(1);\n    var losses = one.sub($labels.mul($predictions).sum(axis, true));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction hingeLoss_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'hingeLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'hingeLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'hingeLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in hingeLoss: ');\n    var one = tensor_ops_1.scalar(1);\n    $labels = tensor_ops_1.scalar(2).mul($labels).sub(one);\n    var losses = one.sub($labels.mul($predictions)).relu();\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction logLoss_(labels, predictions, weights, epsilon, reduction) {\n    if (epsilon === void 0) { epsilon = 1e-7; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'logLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'logLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'logLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in logLoss: ');\n    var one = tensor_ops_1.scalar(1);\n    var epsilonScalar = tensor_ops_1.scalar(epsilon);\n    var losses = $labels.mul($predictions.add(epsilonScalar).log())\n        .neg()\n        .sub(one.sub($labels).mul(one.sub($predictions).add(epsilonScalar).log()));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction sigmoidCrossEntropyWithLogits_(labels, logits) {\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'sigmoidCrossEntropyWithLogits');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'sigmoidCrossEntropyWithLogits');\n    util_1.assertShapesMatch($labels.shape, $logits.shape, 'Error in sigmoidCrossEntropyWithLogits: ');\n    var maxOutput = $logits.relu();\n    var outputXTarget = $logits.mul($labels);\n    var sigmoidOutput = $logits.abs().neg().exp().log1p();\n    return maxOutput.sub(outputXTarget).add(sigmoidOutput);\n}\nfunction sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing, reduction) {\n    if (labelSmoothing === void 0) { labelSmoothing = 0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $multiClassLabels = tensor_util_env_1.convertToTensor(multiClassLabels, 'multiClassLabels', 'sigmoidCrossEntropy');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'sigmoidCrossEntropy');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'sigmoidCrossEntropy');\n    }\n    util_1.assertShapesMatch($multiClassLabels.shape, $logits.shape, 'Error in sigmoidCrossEntropy: ');\n    if (labelSmoothing > 0) {\n        var labelSmoothingScalar = tensor_ops_1.scalar(labelSmoothing);\n        var one = tensor_ops_1.scalar(1);\n        var half = tensor_ops_1.scalar(0.5);\n        $multiClassLabels = $multiClassLabels.mul(one.sub(labelSmoothingScalar))\n            .add(half.mul(labelSmoothingScalar));\n    }\n    var losses = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction huberLoss_(labels, predictions, weights, delta, reduction) {\n    if (delta === void 0) { delta = 1.0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'huberLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'huberLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'huberLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in huberLoss: ');\n    var deltaScalar = tensor_ops_1.scalar(delta);\n    var error = $predictions.sub($labels).abs();\n    var quadratic = binary_ops_1.minimum(error, deltaScalar);\n    var linear = error.sub(quadratic);\n    var losses = tensor_ops_1.scalar(0.5).mul(quadratic.square()).add(deltaScalar.mul(linear));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction softmaxCrossEntropyWithLogits_(labels, logits, dim) {\n    if (dim === void 0) { dim = -1; }\n    if (dim === -1) {\n        dim = logits.rank - 1;\n    }\n    if (dim !== logits.rank - 1) {\n        throw Error(\"Softmax cross entropy along a non-last dimension is not yet \" +\n            (\"supported. Labels / logits was rank \" + logits.rank + \" \") +\n            (\"and dim was \" + dim));\n    }\n    var customOp = globals_1.customGrad(function (labels, logits) {\n        var keepDims = true;\n        var lse = logits.logSumExp([dim], keepDims);\n        var logResult = logits.toFloat().sub(lse);\n        var costVector = logResult.mul(labels).neg();\n        var value = costVector.sum([dim]);\n        var gradFunc = function (dy) {\n            var dyShape = axis_util_1.expandShapeToKeepDim(dy.shape, [dim]);\n            return [\n                dy.reshape(dyShape).mul(labels.toFloat().sub(logResult.exp())),\n                dy.reshape(dyShape).mul(logResult.exp().sub(labels.toFloat())),\n            ];\n        };\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp(labels, logits);\n}\nfunction softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing, reduction) {\n    if (labelSmoothing === void 0) { labelSmoothing = 0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $onehotLabels = tensor_util_env_1.convertToTensor(onehotLabels, 'onehotLabels', 'softmaxCrossEntropy');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'softmaxCrossEntropy');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'softmaxCrossEntropy');\n    }\n    util_1.assertShapesMatch($onehotLabels.shape, $logits.shape, 'Error in softmaxCrossEntropy: ');\n    if (labelSmoothing > 0) {\n        var labelSmoothingScalar = tensor_ops_1.scalar(labelSmoothing);\n        var one = tensor_ops_1.scalar(1);\n        var numClasses = tensor_ops_1.scalar($onehotLabels.shape[1]);\n        $onehotLabels = $onehotLabels.mul(one.sub(labelSmoothingScalar))\n            .add(labelSmoothingScalar.div(numClasses));\n    }\n    var losses = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nexports.absoluteDifference = operation_1.op({ absoluteDifference_: absoluteDifference_ });\nexports.computeWeightedLoss = operation_1.op({ computeWeightedLoss_: computeWeightedLoss_ });\nexports.cosineDistance = operation_1.op({ cosineDistance_: cosineDistance_ });\nexports.hingeLoss = operation_1.op({ hingeLoss_: hingeLoss_ });\nexports.huberLoss = operation_1.op({ huberLoss_: huberLoss_ });\nexports.logLoss = operation_1.op({ logLoss_: logLoss_ });\nexports.meanSquaredError = operation_1.op({ meanSquaredError_: meanSquaredError_ });\nexports.sigmoidCrossEntropy = operation_1.op({ sigmoidCrossEntropy_: sigmoidCrossEntropy_ });\nexports.softmaxCrossEntropy = operation_1.op({ softmaxCrossEntropy_: softmaxCrossEntropy_ });\n"},"sourceMaps":{"js":{"version":3,"file":"loss_ops.js","sourceRoot":"","sources":["../../src/ops/loss_ops.ts"],"names":[],"mappings":";;AAiBA,sCAAsC;AAEtC,sDAAmD;AAEnD,gCAAyD;AAEzD,yCAAiD;AAEjD,2CAAqC;AACrC,yCAA+B;AAC/B,2CAA0C;AAE1C,IAAY,SAKX;AALD,WAAY,SAAS;IACnB,yCAAI,CAAA;IACJ,yCAAI,CAAA;IACJ,uCAAG,CAAA;IACH,6EAAsB,CAAA;AACxB,CAAC,EALW,SAAS,GAAT,iBAAS,KAAT,iBAAS,QAKpB;AAYD,8BACI,MAAoB,EAAE,OAA2B,EACjD,SAA4C;IAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAM,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,qBAAqB,CAAC,CAAC;IACzE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,qBAAqB,CAAC,CAAC;KACvE;IAED,IAAM,YAAY,GAAG,CAAC,QAAQ,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;IAE1E,IAAI,SAAS,KAAK,SAAS,CAAC,IAAI,EAAE;QAChC,OAAO,YAAiB,CAAC;KAC1B;IACD,IAAI,SAAS,KAAK,SAAS,CAAC,GAAG,EAAE;QAC/B,OAAO,YAAY,CAAC,GAAG,EAAE,CAAC;KAC3B;IACD,IAAI,SAAS,KAAK,SAAS,CAAC,IAAI,EAAE;QAChC,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,OAAO,YAAY,CAAC,IAAI,EAAE,CAAC;SAC5B;aAAM;YACL,IAAM,eAAe,GACjB,oBAAa,CAAC,OAAO,CAAC,KAAK,CAAC,GAAG,oBAAa,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC;YACjE,IAAM,MAAM,GAAG,YAAY,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,EAAE,CAAC,CAAC;YACtD,OAAO,eAAe,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,GAAG,CAAC,mBAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;gBACrC,MAAW,CAAC;SAC1C;KACF;IACD,IAAI,SAAS,KAAK,SAAS,CAAC,sBAAsB,EAAE;QAClD,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,OAAO,YAAY,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,mBAAM,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC;SACrD;aAAM;YACL,IAAM,kBAAkB,GAAG,QAAQ,CAAC,GAAG,CAAC,iBAAI,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC;YAE7D,IAAM,WAAW,GACb,kBAAkB,CAAC,QAAQ,CAAC,mBAAM,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,OAAO,EAAE,CAAC;YAC3D,OAAO,YAAY,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;SAC5C;KACF;IAED,MAAM,KAAK,CAAC,wBAAsB,SAAW,CAAC,CAAC;AACjD,CAAC;AAgBD,6BACI,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAC3B,SAA4C;IAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAM,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,oBAAoB,CAAC,CAAC;IACxE,IAAM,YAAY,GACd,iCAAe,CAAC,WAAW,EAAE,aAAa,EAAE,oBAAoB,CAAC,CAAC;IACtE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,oBAAoB,CAAC,CAAC;KACtE;IACD,wBAAiB,CACb,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,+BAA+B,CAAC,CAAC;IAExE,IAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC,GAAG,EAAE,CAAC;IAC/C,OAAO,2BAAmB,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAgBD,2BACI,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAC3B,SAA4C;IAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAM,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,kBAAkB,CAAC,CAAC;IACtE,IAAM,YAAY,GACd,iCAAe,CAAC,WAAW,EAAE,aAAa,EAAE,kBAAkB,CAAC,CAAC;IACpE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,kBAAkB,CAAC,CAAC;KACpE;IACD,wBAAiB,CACb,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,6BAA6B,CAAC,CAAC;IAEtE,IAAM,MAAM,GAAG,OAAO,CAAC,iBAAiB,CAAC,YAAY,CAAC,CAAC;IACvD,OAAO,2BAAmB,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAiBD,yBACI,MAAoB,EAAE,WAAyB,EAAE,IAAY,EAC7D,OAA2B,EAC3B,SAA4C;IAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAM,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,gBAAgB,CAAC,CAAC;IACpE,IAAM,YAAY,GACd,iCAAe,CAAC,WAAW,EAAE,aAAa,EAAE,gBAAgB,CAAC,CAAC;IAClE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,gBAAgB,CAAC,CAAC;KAClE;IACD,wBAAiB,CACb,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,2BAA2B,CAAC,CAAC;IAEpE,IAAM,GAAG,GAAG,mBAAM,CAAC,CAAC,CAAC,CAAC;IACtB,IAAM,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC;IAClE,OAAO,2BAAmB,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAgBD,oBACI,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAC3B,SAA4C;IAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAI,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,WAAW,CAAC,CAAC;IAC7D,IAAM,YAAY,GAAG,iCAAe,CAAC,WAAW,EAAE,aAAa,EAAE,WAAW,CAAC,CAAC;IAC9E,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,WAAW,CAAC,CAAC;KAC7D;IACD,wBAAiB,CAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,sBAAsB,CAAC,CAAC;IAE7E,IAAM,GAAG,GAAG,mBAAM,CAAC,CAAC,CAAC,CAAC;IAEtB,OAAO,GAAG,mBAAM,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;IAC1C,IAAM,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;IACzD,OAAO,2BAAmB,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAiBD,kBACI,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAAE,OAAc,EAC3C,SAA4C;IADf,wBAAA,EAAA,cAAc;IAC3C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAM,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;IAC7D,IAAM,YAAY,GAAG,iCAAe,CAAC,WAAW,EAAE,aAAa,EAAE,SAAS,CAAC,CAAC;IAC5E,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC;KAC3D;IACD,wBAAiB,CAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,oBAAoB,CAAC,CAAC;IAE3E,IAAM,GAAG,GAAG,mBAAM,CAAC,CAAC,CAAC,CAAC;IACtB,IAAM,aAAa,GAAG,mBAAM,CAAC,OAAO,CAAC,CAAC;IACtC,IAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC,GAAG,EAAE,CAAC;SAC7C,GAAG,EAAE;SACL,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,GAAG,CACrB,GAAG,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;IACxE,OAAO,2BAAmB,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAED,wCACI,MAAoB,EAAE,MAAoB;IAC5C,IAAM,OAAO,GACT,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,+BAA+B,CAAC,CAAC;IACvE,IAAM,OAAO,GACT,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,+BAA+B,CAAC,CAAC;IACvE,wBAAiB,CACb,OAAO,CAAC,KAAK,EAAE,OAAO,CAAC,KAAK,EAAE,0CAA0C,CAAC,CAAC;IAsB9E,IAAM,SAAS,GAAG,OAAO,CAAC,IAAI,EAAE,CAAC;IACjC,IAAM,aAAa,GAAG,OAAO,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC;IAC3C,IAAM,aAAa,GAAG,OAAO,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,KAAK,EAAE,CAAC;IAExD,OAAO,SAAS,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC;AACzD,CAAC;AAsBD,8BACI,gBAA8B,EAAE,MAAoB,EACpD,OAA2B,EAAE,cAAkB,EAC/C,SAA4C;IADf,+BAAA,EAAA,kBAAkB;IAC/C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAI,iBAAiB,GAAG,iCAAe,CACnC,gBAAgB,EAAE,kBAAkB,EAAE,qBAAqB,CAAC,CAAC;IACjE,IAAM,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,qBAAqB,CAAC,CAAC;IACzE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,qBAAqB,CAAC,CAAC;KACvE;IACD,wBAAiB,CACb,iBAAiB,CAAC,KAAK,EAAE,OAAO,CAAC,KAAK,EAAE,gCAAgC,CAAC,CAAC;IAE9E,IAAI,cAAc,GAAG,CAAC,EAAE;QACtB,IAAM,oBAAoB,GAAG,mBAAM,CAAC,cAAc,CAAC,CAAC;QACpD,IAAM,GAAG,GAAG,mBAAM,CAAC,CAAC,CAAC,CAAC;QACtB,IAAM,IAAI,GAAG,mBAAM,CAAC,GAAG,CAAC,CAAC;QAEzB,iBAAiB,GAAG,iBAAiB,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,oBAAoB,CAAC,CAAC;aAC/C,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,oBAAoB,CAAC,CAAC,CAAC;KAC9D;IACD,IAAM,MAAM,GAAG,8BAA8B,CAAC,iBAAiB,EAAE,OAAO,CAAC,CAAC;IAE1E,OAAO,2BAAmB,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAiBD,oBACI,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAAE,KAAW,EACxC,SAA4C;IADf,sBAAA,EAAA,WAAW;IACxC,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAM,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,WAAW,CAAC,CAAC;IAC/D,IAAM,YAAY,GAAG,iCAAe,CAAC,WAAW,EAAE,aAAa,EAAE,WAAW,CAAC,CAAC;IAC9E,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,WAAW,CAAC,CAAC;KAC7D;IACD,wBAAiB,CAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,sBAAsB,CAAC,CAAC;IAE7E,IAAM,WAAW,GAAG,mBAAM,CAAC,KAAK,CAAC,CAAC;IAClC,IAAM,KAAK,GAAG,YAAY,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,GAAG,EAAE,CAAC;IAC9C,IAAM,SAAS,GAAG,oBAAO,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;IAC9C,IAAM,MAAM,GAAG,KAAK,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC;IAEpC,IAAM,MAAM,GACR,mBAAM,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,SAAS,CAAC,MAAM,EAAE,CAAC,CAAC,GAAG,CAAC,WAAW,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC;IACrE,OAAO,2BAAmB,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AA0BD,wCACI,MAAS,EAAE,MAAS,EAAE,GAAQ;IAAR,oBAAA,EAAA,OAAO,CAAC;IAChC,IAAI,GAAG,KAAK,CAAC,CAAC,EAAE;QACd,GAAG,GAAG,MAAM,CAAC,IAAI,GAAG,CAAC,CAAC;KACvB;IAED,IAAI,GAAG,KAAK,MAAM,CAAC,IAAI,GAAG,CAAC,EAAE;QAC3B,MAAM,KAAK,CACP,8DAA8D;aAC9D,yCAAuC,MAAM,CAAC,IAAI,MAAG,CAAA;aACrD,iBAAe,GAAK,CAAA,CAAC,CAAC;KAC3B;IAED,IAAM,QAAQ,GAAG,oBAAU,CAAC,UAAC,MAAM,EAAE,MAAM;QAIzC,IAAM,QAAQ,GAAG,IAAI,CAAC;QACtB,IAAM,GAAG,GAAG,MAAM,CAAC,SAAS,CAAC,CAAC,GAAG,CAAC,EAAE,QAAQ,CAAC,CAAC;QAE9C,IAAM,SAAS,GAAG,MAAM,CAAC,OAAO,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QAC5C,IAAM,UAAU,GAAG,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,CAAC;QAE/C,IAAM,KAAK,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAM,CAAC;QAEzC,IAAM,QAAQ,GAAG,UAAC,EAAK;YACrB,IAAM,OAAO,GAAG,gCAAoB,CAAC,EAAE,CAAC,KAAK,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;YACtD,OAAO;gBACL,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC,GAAG,CAAC,SAAS,CAAC,GAAG,EAAE,CAAC,CAAC;gBAC9D,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,GAAG,CAAC,SAAS,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC,CAAC;aAC/D,CAAC;QACJ,CAAC,CAAC;QACF,OAAO,EAAC,KAAK,OAAA,EAAE,QAAQ,UAAA,EAAC,CAAC;IAC3B,CAAC,CAAC,CAAC;IAEH,OAAO,QAAQ,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;AAClC,CAAC;AAoBD,8BACI,YAA0B,EAAE,MAAoB,EAChD,OAA2B,EAAE,cAAkB,EAC/C,SAA4C;IADf,+BAAA,EAAA,kBAAkB;IAC/C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;IAC9C,IAAI,aAAa,GACb,iCAAe,CAAC,YAAY,EAAE,cAAc,EAAE,qBAAqB,CAAC,CAAC;IACzE,IAAM,OAAO,GAAG,iCAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,qBAAqB,CAAC,CAAC;IACzE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAE5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,GAAG,iCAAe,CAAC,OAAO,EAAE,SAAS,EAAE,qBAAqB,CAAC,CAAC;KACvE;IAED,wBAAiB,CACb,aAAa,CAAC,KAAK,EAAE,OAAO,CAAC,KAAK,EAAE,gCAAgC,CAAC,CAAC;IAE1E,IAAI,cAAc,GAAG,CAAC,EAAE;QACtB,IAAM,oBAAoB,GAAG,mBAAM,CAAC,cAAc,CAAC,CAAC;QACpD,IAAM,GAAG,GAAG,mBAAM,CAAC,CAAC,CAAC,CAAC;QACtB,IAAM,UAAU,GAAG,mBAAM,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QAElD,aAAa,GAAG,aAAa,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,oBAAoB,CAAC,CAAC;aAC3C,GAAG,CAAC,oBAAoB,CAAC,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC;KAChE;IAED,IAAM,MAAM,GAAG,8BAA8B,CAAC,aAAa,EAAE,OAAO,CAAC,CAAC;IAEtE,OAAO,2BAAmB,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAEY,QAAA,kBAAkB,GAAG,cAAE,CAAC,EAAC,mBAAmB,qBAAA,EAAC,CAAC,CAAC;AAC/C,QAAA,mBAAmB,GAAG,cAAE,CAAC,EAAC,oBAAoB,sBAAA,EAAC,CAAC,CAAC;AACjD,QAAA,cAAc,GAAG,cAAE,CAAC,EAAC,eAAe,iBAAA,EAAC,CAAC,CAAC;AACvC,QAAA,SAAS,GAAG,cAAE,CAAC,EAAC,UAAU,YAAA,EAAC,CAAC,CAAC;AAC7B,QAAA,SAAS,GAAG,cAAE,CAAC,EAAC,UAAU,YAAA,EAAC,CAAC,CAAC;AAC7B,QAAA,OAAO,GAAG,cAAE,CAAC,EAAC,QAAQ,UAAA,EAAC,CAAC,CAAC;AACzB,QAAA,gBAAgB,GAAG,cAAE,CAAC,EAAC,iBAAiB,mBAAA,EAAC,CAAC,CAAC;AAC3C,QAAA,mBAAmB,GAAG,cAAE,CAAC,EAAC,oBAAoB,sBAAA,EAAC,CAAC,CAAC;AACjD,QAAA,mBAAmB,GAAG,cAAE,CAAC,EAAC,oBAAoB,sBAAA,EAAC,CAAC,CAAC","sourcesContent":[null]}},"error":null,"hash":"63f943512993d63c95ed5503d5b02a1d","cacheData":{"env":{}}}